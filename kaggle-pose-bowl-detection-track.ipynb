{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7879433,"sourceType":"datasetVersion","datasetId":4552256}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Детекция на примере `yolov5`","metadata":{"id":"QRkFXZXeWsWn"}},{"cell_type":"markdown","source":"## Подготовка","metadata":{"id":"CxBtH_izcl6G"}},{"cell_type":"markdown","source":"Клонируем репозиторий [`ultralytics/yolov5`](https://github.com/ultralytics/yolov5)","metadata":{"id":"s4b112SSbR8i"}},{"cell_type":"code","source":"!git clone https://github.com/ultralytics/yolov5.git","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3468,"status":"ok","timestamp":1713001137397,"user":{"displayName":"Даниил Владимирович Маковецкий","userId":"12330401444605609021"},"user_tz":-420},"id":"LK1jnJDXWx06","outputId":"b5337b6d-178d-4366-832b-d06587937a65","execution":{"iopub.status.busy":"2024-04-13T17:47:48.502022Z","iopub.execute_input":"2024-04-13T17:47:48.502387Z","iopub.status.idle":"2024-04-13T17:47:50.813372Z","shell.execute_reply.started":"2024-04-13T17:47:48.502351Z","shell.execute_reply":"2024-04-13T17:47:50.812457Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Cloning into 'yolov5'...\nremote: Enumerating objects: 16531, done.\u001b[K\nremote: Counting objects: 100% (9/9), done.\u001b[K\nremote: Compressing objects: 100% (9/9), done.\u001b[K\nremote: Total 16531 (delta 1), reused 5 (delta 0), pack-reused 16522\u001b[K\nReceiving objects: 100% (16531/16531), 15.05 MiB | 30.29 MiB/s, done.\nResolving deltas: 100% (11354/11354), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd yolov5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1713001137397,"user":{"displayName":"Даниил Владимирович Маковецкий","userId":"12330401444605609021"},"user_tz":-420},"id":"DX5PtcKAb6b-","outputId":"57596118-7d39-4e1e-98d0-728492285f4a","execution":{"iopub.status.busy":"2024-04-13T17:47:50.815186Z","iopub.execute_input":"2024-04-13T17:47:50.815503Z","iopub.status.idle":"2024-04-13T17:47:50.822047Z","shell.execute_reply.started":"2024-04-13T17:47:50.815475Z","shell.execute_reply":"2024-04-13T17:47:50.821156Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"/kaggle/working/yolov5/yolov5/yolov5\n","output_type":"stream"}]},{"cell_type":"code","source":"%ls","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":397,"status":"ok","timestamp":1713001137792,"user":{"displayName":"Даниил Владимирович Маковецкий","userId":"12330401444605609021"},"user_tz":-420},"id":"OTcQ7PdOb-fA","outputId":"f4df7ee0-23d2-4360-822e-1ef8f3e9c5ec","execution":{"iopub.status.busy":"2024-04-13T17:47:50.823256Z","iopub.execute_input":"2024-04-13T17:47:50.823537Z","iopub.status.idle":"2024-04-13T17:47:51.763162Z","shell.execute_reply.started":"2024-04-13T17:47:50.823514Z","shell.execute_reply":"2024-04-13T17:47:51.762079Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"CITATION.cff     README.zh-CN.md  detect.py   pyproject.toml    tutorial.ipynb\nCONTRIBUTING.md  benchmarks.py    export.py   requirements.txt  \u001b[0m\u001b[01;34mutils\u001b[0m/\nLICENSE          \u001b[01;34mclassify\u001b[0m/        hubconf.py  \u001b[01;34msegment\u001b[0m/          val.py\nREADME.md        \u001b[01;34mdata\u001b[0m/            \u001b[01;34mmodels\u001b[0m/     train.py\n","output_type":"stream"}]},{"cell_type":"code","source":"!python -m pip install -r requirements.txt","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":90762,"status":"ok","timestamp":1713001228552,"user":{"displayName":"Даниил Владимирович Маковецкий","userId":"12330401444605609021"},"user_tz":-420},"id":"ltqho5eNcc01","outputId":"f60382db-9a8c-408b-8ede-aa42122b109a","execution":{"iopub.status.busy":"2024-04-13T17:47:51.766258Z","iopub.execute_input":"2024-04-13T17:47:51.766575Z","iopub.status.idle":"2024-04-13T17:48:04.200105Z","shell.execute_reply.started":"2024-04-13T17:47:51.766544Z","shell.execute_reply":"2024-04-13T17:48:04.198901Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Requirement already satisfied: gitpython>=3.1.30 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (3.1.41)\nRequirement already satisfied: matplotlib>=3.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (3.7.5)\nRequirement already satisfied: numpy>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.26.4)\nRequirement already satisfied: opencv-python>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (4.9.0.80)\nRequirement already satisfied: pillow>=10.3.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (10.3.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (5.9.3)\nRequirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (6.0.1)\nRequirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (2.31.0)\nRequirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (1.11.4)\nRequirement already satisfied: thop>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\nRequirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (2.1.2)\nRequirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (0.16.2)\nRequirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (4.66.1)\nRequirement already satisfied: ultralytics>=8.0.232 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (8.1.47)\nRequirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 27)) (2.1.4)\nRequirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 28)) (0.12.2)\nRequirement already satisfied: setuptools>=65.5.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 42)) (69.0.3)\nRequirement already satisfied: wheel>=0.38.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 50)) (0.42.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.11)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.9.0.post0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2024.2.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2024.3.0)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics>=8.0.232->-r requirements.txt (line 18)) (9.0.0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.4)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Пробуем запустить","metadata":{"id":"lsyvQ1XZdQOR"}},{"cell_type":"markdown","source":"Сначала попробуем запустить код с их обученной моделью, а потом будем пробовать запускать своё обучение","metadata":{"id":"iY5VEbXfckRS"}},{"cell_type":"code","source":"# %cat data/Objects365.yaml","metadata":{"id":"Mw-00CMuetzw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713001476554,"user_tz":-420,"elapsed":406,"user":{"displayName":"Даниил Владимирович Маковецкий","userId":"12330401444605609021"}},"outputId":"3e09f8b2-220c-4465-e242-05ec2ba6c376","execution":{"iopub.status.busy":"2024-04-13T17:48:04.201720Z","iopub.execute_input":"2024-04-13T17:48:04.202052Z","iopub.status.idle":"2024-04-13T17:48:04.206662Z","shell.execute_reply.started":"2024-04-13T17:48:04.202022Z","shell.execute_reply":"2024-04-13T17:48:04.205730Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# %ls data/Objects365.yaml","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":279,"status":"ok","timestamp":1712997322854,"user":{"displayName":"Даниил Владимирович Маковецкий","userId":"12330401444605609021"},"user_tz":-420},"id":"RyWNHK3hf9TC","outputId":"e553d80b-090f-4a3d-b669-f3b48ef3cf56","execution":{"iopub.status.busy":"2024-04-13T17:48:04.207910Z","iopub.execute_input":"2024-04-13T17:48:04.208257Z","iopub.status.idle":"2024-04-13T17:48:04.216903Z","shell.execute_reply.started":"2024-04-13T17:48:04.208223Z","shell.execute_reply":"2024-04-13T17:48:04.216124Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"!python val.py --weights yolov5m.pt --data data/Objects365.yaml --imgsz 640 --device 0  # cuda:0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25779,"status":"ok","timestamp":1712997349398,"user":{"displayName":"Даниил Владимирович Маковецкий","userId":"12330401444605609021"},"user_tz":-420},"id":"WtoZAOrhgBPr","outputId":"20eb40c4-e75a-4065-d39b-5cd1a8cea2c1","execution":{"iopub.status.busy":"2024-04-13T17:48:04.217878Z","iopub.execute_input":"2024-04-13T17:48:04.218136Z","iopub.status.idle":"2024-04-13T17:51:06.181606Z","shell.execute_reply.started":"2024-04-13T17:48:04.218114Z","shell.execute_reply":"2024-04-13T17:51:06.180466Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mval: \u001b[0mdata=data/Objects365.yaml, weights=['yolov5m.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=0, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\nYOLOv5 🚀 v7.0-298-g21f8f94d Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\n\nDownloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m.pt to yolov5m.pt...\n100%|███████████████████████████████████████| 40.8M/40.8M [00:00<00:00, 305MB/s]\n\nFusing layers... \nYOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients, 48.9 GFLOPs\n\nDataset not found ⚠️, missing paths ['/kaggle/working/yolov5/yolov5/datasets/Objects365/images/val']\nProcessing train in 51 patches ...\nDownloading https://dorc.ks3-cn-beijing.ksyun.com/data-set/2020Objects365%E6%95%B0%E6%8D%AE%E9%9B%86/train/zhiyuan_objv2_train.tar.gz to /kaggle/working/yolov5/yolov5/datasets/Objects365/zhiyuan_objv2_train.tar.gz...\n100%|██████████████████████████████████████| 1.24G/1.24G [02:02<00:00, 10.9MB/s]\nUnzipping /kaggle/working/yolov5/yolov5/datasets/Objects365/zhiyuan_objv2_train.tar.gz...\ntar: zhiyuan_objv2_train.json: Wrote only 6656 of 10240 bytes\ntar: Exiting with failure status due to previous errors\nTraceback (most recent call last):\n  File \"/kaggle/working/yolov5/yolov5/yolov5/val.py\", line 438, in <module>\n    main(opt)\n  File \"/kaggle/working/yolov5/yolov5/yolov5/val.py\", line 409, in main\n    run(**vars(opt))\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n    return func(*args, **kwargs)\n  File \"/kaggle/working/yolov5/yolov5/yolov5/val.py\", line 178, in run\n    data = check_dataset(data)  # check\n  File \"/kaggle/working/yolov5/yolov5/yolov5/utils/general.py\", line 575, in check_dataset\n    r = exec(s, {\"yaml\": data})  # return None\n  File \"<string>\", line 23, in <module>\n  File \"/kaggle/working/yolov5/yolov5/yolov5/utils/general.py\", line 691, in download\n    download_one(u, dir)\n  File \"/kaggle/working/yolov5/yolov5/yolov5/utils/general.py\", line 676, in download_one\n    subprocess.run([\"tar\", \"xf\", f, \"--directory\", f.parent], check=True)  # unzip\n  File \"/opt/conda/lib/python3.10/subprocess.py\", line 526, in run\n    raise CalledProcessError(retcode, process.args,\nsubprocess.CalledProcessError: Command '['tar', 'xf', PosixPath('/kaggle/working/yolov5/yolov5/datasets/Objects365/zhiyuan_objv2_train.tar.gz'), '--directory', PosixPath('/kaggle/working/yolov5/yolov5/datasets/Objects365')]' returned non-zero exit status 2.\n","output_type":"stream"}]},{"cell_type":"code","source":"%ls ../datasets/Objects365","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1712997349399,"user":{"displayName":"Даниил Владимирович Маковецкий","userId":"12330401444605609021"},"user_tz":-420},"id":"G8aJbjGYg0se","outputId":"33ffe1bd-65c4-4e31-8ddf-41534a760cc5","execution":{"iopub.status.busy":"2024-04-13T17:51:06.183301Z","iopub.execute_input":"2024-04-13T17:51:06.183735Z","iopub.status.idle":"2024-04-13T17:51:07.128472Z","shell.execute_reply.started":"2024-04-13T17:51:06.183698Z","shell.execute_reply":"2024-04-13T17:51:07.127461Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"\u001b[0m\u001b[01;34mimages\u001b[0m/  \u001b[01;34mlabels\u001b[0m/  \u001b[01;32mzhiyuan_objv2_train.json\u001b[0m*  zhiyuan_objv2_train.tar.gz\n","output_type":"stream"}]},{"cell_type":"code","source":"# %ls ../datasets/coco128/images/train2017","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":259,"status":"ok","timestamp":1712997370270,"user":{"displayName":"Даниил Владимирович Маковецкий","userId":"12330401444605609021"},"user_tz":-420},"id":"bH7w0DDQhMck","outputId":"22d55272-3184-485d-9c4e-ce58117021d3","execution":{"iopub.status.busy":"2024-04-13T17:51:07.129981Z","iopub.execute_input":"2024-04-13T17:51:07.130282Z","iopub.status.idle":"2024-04-13T17:51:07.134485Z","shell.execute_reply.started":"2024-04-13T17:51:07.130254Z","shell.execute_reply":"2024-04-13T17:51:07.133633Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# %ls ../datasets/coco128/labels/train2017/","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":398,"status":"ok","timestamp":1712997376499,"user":{"displayName":"Даниил Владимирович Маковецкий","userId":"12330401444605609021"},"user_tz":-420},"id":"AZ3VZvJdhZjZ","outputId":"fffb704e-d098-4d52-c701-3dcbf527eba8","execution":{"iopub.status.busy":"2024-04-13T17:51:07.137948Z","iopub.execute_input":"2024-04-13T17:51:07.138224Z","iopub.status.idle":"2024-04-13T17:51:07.144679Z","shell.execute_reply.started":"2024-04-13T17:51:07.138192Z","shell.execute_reply":"2024-04-13T17:51:07.143836Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"Посмотрим на то, что представляют из себя файлы с аннотациями","metadata":{"id":"cKCbWt1Ai_Wg"}},{"cell_type":"code","source":"# %cat  ../datasets/coco128/labels/train2017/000000000009.txt","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":265,"status":"ok","timestamp":1712997379430,"user":{"displayName":"Даниил Владимирович Маковецкий","userId":"12330401444605609021"},"user_tz":-420},"id":"PGjpngGEhn9i","outputId":"64658ad4-40f1-4742-b9d6-8b2c59de0fd1","execution":{"iopub.status.busy":"2024-04-13T17:51:07.145717Z","iopub.execute_input":"2024-04-13T17:51:07.146056Z","iopub.status.idle":"2024-04-13T17:51:07.153988Z","shell.execute_reply.started":"2024-04-13T17:51:07.146024Z","shell.execute_reply":"2024-04-13T17:51:07.153052Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"Формат разметки, который здесь используется, называется `yolo`-форматом:\n\n`[cls, x_center / img_w, y_center / img_h, w / img_w, h / img_h]`\n\nЕсть и другие популярные форматы разметки, например, `coco`-формат. А вот что значат цифры в начале:","metadata":{"id":"knNtBV7Okixu"}},{"cell_type":"markdown","source":"```text\n45: bowl\n46: banana\n47: apple\n48: sandwich\n49: orange\n50: broccoli\n```","metadata":{"id":"4Hpx6CROjOq9"}},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n# from google.colab.patches import cv2_imshow","metadata":{"id":"KDouye3ujH3S","executionInfo":{"status":"ok","timestamp":1712997385342,"user_tz":-420,"elapsed":260,"user":{"displayName":"Даниил Владимирович Маковецкий","userId":"12330401444605609021"}},"execution":{"iopub.status.busy":"2024-04-13T17:52:12.701009Z","iopub.execute_input":"2024-04-13T17:52:12.701423Z","iopub.status.idle":"2024-04-13T17:52:12.706147Z","shell.execute_reply.started":"2024-04-13T17:52:12.701381Z","shell.execute_reply":"2024-04-13T17:52:12.705176Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# img = cv2.imread('../datasets/coco128/images/train2017/000000000009.jpg')\n# cv2_imshow(img)\n# plt.show()","metadata":{"id":"__oqxyQEjYtm","colab":{"base_uri":"https://localhost:8080/","height":497},"executionInfo":{"status":"ok","timestamp":1712997388646,"user_tz":-420,"elapsed":798,"user":{"displayName":"Даниил Владимирович Маковецкий","userId":"12330401444605609021"}},"outputId":"654e99ef-51c1-45f9-89bf-d878b98ceb1e","execution":{"iopub.status.busy":"2024-04-13T17:52:12.708271Z","iopub.execute_input":"2024-04-13T17:52:12.709214Z","iopub.status.idle":"2024-04-13T17:52:12.717545Z","shell.execute_reply.started":"2024-04-13T17:52:12.709181Z","shell.execute_reply":"2024-04-13T17:52:12.716628Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# !python detect.py --weights yolov5m.pt --source ../datasets/coco128/images/train2017/000000000009.jpg --name some_name","metadata":{"executionInfo":{"elapsed":7638,"status":"ok","timestamp":1712997413751,"user":{"displayName":"Даниил Владимирович Маковецкий","userId":"12330401444605609021"},"user_tz":-420},"id":"caGidF_OjnVV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"745c7860-c8b5-427c-b9c0-f30772a9bd45","execution":{"iopub.status.busy":"2024-04-13T17:52:12.718841Z","iopub.execute_input":"2024-04-13T17:52:12.719350Z","iopub.status.idle":"2024-04-13T17:52:12.726209Z","shell.execute_reply.started":"2024-04-13T17:52:12.719316Z","shell.execute_reply":"2024-04-13T17:52:12.725444Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# img = cv2.imread('runs/detect/some_name/000000000009.jpg')\n# cv2_imshow(img)\n# plt.show()","metadata":{"executionInfo":{"elapsed":1079,"status":"ok","timestamp":1712997449539,"user":{"displayName":"Даниил Владимирович Маковецкий","userId":"12330401444605609021"},"user_tz":-420},"id":"7Dxx9Ew2kK2y","colab":{"base_uri":"https://localhost:8080/","height":497},"outputId":"389f287b-72a3-4362-a958-22ec1eda9b78","execution":{"iopub.status.busy":"2024-04-13T17:52:12.727534Z","iopub.execute_input":"2024-04-13T17:52:12.728380Z","iopub.status.idle":"2024-04-13T17:52:12.735480Z","shell.execute_reply.started":"2024-04-13T17:52:12.728351Z","shell.execute_reply":"2024-04-13T17:52:12.734723Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"Также можно запустить `detect.py` не только на отдельном изображении, но и на папке с изображениями, на потоке, на изображении из сети и т.п.","metadata":{"id":"50CdgwqFkgD5"}},{"cell_type":"markdown","source":"## Как запустить своё обучение","metadata":{"id":"k3m_Lz43oxvr"}},{"cell_type":"markdown","source":"Чтобы запустить своё обучение, надо:\n\n- Подготовить датасет в `yolo`-формате, создать свой конфиг с путями до данных вида `data/my_data.yaml`. Примеры того, как организовывать файлы в датасет, можно посмотреть в [`data/coco.yaml`](https://github.com/ultralytics/yolov5/blob/master/data/coco.yaml) и [`data/VOC.yaml`](https://github.com/ultralytics/yolov5/blob/master/data/VOC.yaml)\n- Создать файлик с конфигом, в котором будут прописаны параметры для тренировки, вида `data/hyps/my_hyps.yaml`. Для начала можно попробовать запустить со стандартным [конфигом](https://github.com/ultralytics/yolov5/blob/master/data/hyps/hyp.scratch-low.yaml)\n- Стартовать с весов `yolov5s`, если будете тренировать yolo small; `yolov5n`, если yolo nano, и т.д.\n![](https://github.com/ultralytics/yolov5/releases/download/v1.0/model_comparison.png)\n- Лучше передавать в `--name` какое-то адекватное название, которое описывает суть эксперимента, чтобы не перепутать потом их между собой\n- Графики можно смотреть во время обучения, для этого надо запустить в терминале что-то типа:\n\n  ` tensorboard --logdir ./runs/train/`\n\n  и перейти по ссылке в браузере\n\nПример:","metadata":{"id":"5X9PQnjLpFPI"}},{"cell_type":"code","source":"!pip install roboflow\n\nfrom roboflow import Roboflow\nrf = Roboflow(api_key=\"vVzgCl7OcCV2hguH2FcC\")\nproject = rf.workspace(\"cs474-ug2-vehicle-detection\").project(\"object-detection-um7ee\")\nversion = project.version(3)\ndataset = version.download(\"yolov5\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"3yU2Fwc_ttzG","executionInfo":{"status":"ok","timestamp":1713004234850,"user_tz":-420,"elapsed":52554,"user":{"displayName":"Даниил Владимирович Маковецкий","userId":"12330401444605609021"}},"outputId":"96b9bd22-bed0-4326-83b9-3609ac4bbacc","execution":{"iopub.status.busy":"2024-04-13T18:06:37.805515Z","iopub.execute_input":"2024-04-13T18:06:37.805936Z","iopub.status.idle":"2024-04-13T18:07:20.738578Z","shell.execute_reply.started":"2024-04-13T18:06:37.805900Z","shell.execute_reply":"2024-04-13T18:07:20.737386Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Requirement already satisfied: roboflow in /opt/conda/lib/python3.10/site-packages (1.1.27)\nRequirement already satisfied: certifi==2023.7.22 in /opt/conda/lib/python3.10/site-packages (from roboflow) (2023.7.22)\nRequirement already satisfied: chardet==4.0.0 in /opt/conda/lib/python3.10/site-packages (from roboflow) (4.0.0)\nRequirement already satisfied: cycler==0.10.0 in /opt/conda/lib/python3.10/site-packages (from roboflow) (0.10.0)\nRequirement already satisfied: idna==2.10 in /opt/conda/lib/python3.10/site-packages (from roboflow) (2.10)\nRequirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.4.5)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from roboflow) (3.7.5)\nRequirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.26.4)\nRequirement already satisfied: opencv-python-headless==4.8.0.74 in /opt/conda/lib/python3.10/site-packages (from roboflow) (4.8.0.74)\nRequirement already satisfied: Pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from roboflow) (10.3.0)\nRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from roboflow) (2.9.0.post0)\nRequirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.0.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from roboflow) (2.31.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.16.0)\nRequirement already satisfied: urllib3>=1.26.6 in /opt/conda/lib/python3.10/site-packages (from roboflow) (1.26.18)\nRequirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from roboflow) (4.66.1)\nRequirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from roboflow) (6.0.1)\nRequirement already satisfied: requests-toolbelt in /opt/conda/lib/python3.10/site-packages (from roboflow) (0.10.1)\nRequirement already satisfied: python-magic in /opt/conda/lib/python3.10/site-packages (from roboflow) (0.4.27)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (1.2.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (4.47.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (21.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->roboflow) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->roboflow) (3.3.2)\nloading Roboflow workspace...\nloading Roboflow project...\n","output_type":"stream"},{"name":"stderr","text":"Downloading Dataset Version Zip in Object-Detection-3 to yolov5pytorch:: 100%|██████████| 665644/665644 [00:25<00:00, 26261.46it/s]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"\nExtracting Dataset Version Zip to Object-Detection-3 in yolov5pytorch:: 100%|██████████| 7882/7882 [00:02<00:00, 3920.23it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd yolov5\n!ls","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"puXdMZDrupqX","executionInfo":{"status":"ok","timestamp":1712997989513,"user_tz":-420,"elapsed":269,"user":{"displayName":"Даниил Владимирович Маковецкий","userId":"12330401444605609021"}},"outputId":"deb930bb-7b64-4320-ece7-0749d51aa5bf","execution":{"iopub.status.busy":"2024-04-13T17:52:34.609961Z","iopub.status.idle":"2024-04-13T17:52:34.610465Z","shell.execute_reply.started":"2024-04-13T17:52:34.610189Z","shell.execute_reply":"2024-04-13T17:52:34.610209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python train.py --data Object-Detection-3/data.yaml --hyp data/hyps/hyp.scratch-high.yaml --weights yolov5m.pt \\\n--epochs 50 --batch-size 64 --optimizer SGD --name lab2_small  --imgsz 1500","metadata":{"id":"gfwo7UJdkcVi","execution":{"iopub.status.busy":"2024-04-13T18:27:37.649310Z","iopub.execute_input":"2024-04-13T18:27:37.650210Z","iopub.status.idle":"2024-04-13T18:28:53.460215Z","shell.execute_reply.started":"2024-04-13T18:27:37.650170Z","shell.execute_reply":"2024-04-13T18:28:53.459161Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n2024-04-13 18:27:46.069423: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-13 18:27:46.069494: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-13 18:27:46.071002: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5m.pt, cfg=, data=Object-Detection-3/data.yaml, hyp=data/hyps/hyp.scratch-high.yaml, epochs=50, batch_size=64, imgsz=1500, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=lab2_small, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\nYOLOv5 🚀 v7.0-298-g21f8f94d Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15102MiB)\n\n\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.1, copy_paste=0.1\n\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\nDownloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n100%|████████████████████████████████████████| 755k/755k [00:00<00:00, 39.1MB/s]\nOverriding model.yaml nc=80 with nc=1\n\n                 from  n    params  module                                  arguments                     \n  0                -1  1      5280  models.common.Conv                      [3, 48, 6, 2, 2]              \n  1                -1  1     41664  models.common.Conv                      [48, 96, 3, 2]                \n  2                -1  2     65280  models.common.C3                        [96, 96, 2]                   \n  3                -1  1    166272  models.common.Conv                      [96, 192, 3, 2]               \n  4                -1  4    444672  models.common.C3                        [192, 192, 4]                 \n  5                -1  1    664320  models.common.Conv                      [192, 384, 3, 2]              \n  6                -1  6   2512896  models.common.C3                        [384, 384, 6]                 \n  7                -1  1   2655744  models.common.Conv                      [384, 768, 3, 2]              \n  8                -1  2   4134912  models.common.C3                        [768, 768, 2]                 \n  9                -1  1   1476864  models.common.SPPF                      [768, 768, 5]                 \n 10                -1  1    295680  models.common.Conv                      [768, 384, 1, 1]              \n 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n 13                -1  2   1182720  models.common.C3                        [768, 384, 2, False]          \n 14                -1  1     74112  models.common.Conv                      [384, 192, 1, 1]              \n 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n 17                -1  2    296448  models.common.C3                        [384, 192, 2, False]          \n 18                -1  1    332160  models.common.Conv                      [192, 192, 3, 2]              \n 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n 20                -1  2   1035264  models.common.C3                        [384, 384, 2, False]          \n 21                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n 23                -1  2   4134912  models.common.C3                        [768, 768, 2, False]          \n 24      [17, 20, 23]  1     24246  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [192, 384, 768]]\nModel summary: 291 layers, 20871318 parameters, 20871318 gradients, 48.2 GFLOPs\n\nTransferred 475/481 items from yolov5m.pt\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\nWARNING ⚠️ --img-size 1500 must be multiple of max stride 32, updating to 1504\n\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 79 weight(decay=0.0), 82 weight(decay=0.0005), 82 bias\nWARNING ⚠️ DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\nSee Multi-GPU Tutorial at https://docs.ultralytics.com/yolov5/tutorials/multi_gpu_training to get started.\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yolov5/Object-Detection-3/train/labels... 3115 i\u001b[0m\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/yolov5/Object-Detection-3/train/labels.cache\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yolov5/Object-Detection-3/valid/labels... 802 imag\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/yolov5/Object-Detection-3/valid/labels.cache\n\n\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.72 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\nPlotting labels to runs/train/lab2_small/labels.jpg... \n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\nImage sizes 1504 train, 1504 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/train/lab2_small\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n  0%|          | 0/49 [00:13<?, ?it/s]\nTraceback (most recent call last):\n  File \"/kaggle/working/yolov5/train.py\", line 848, in <module>\n    main(opt)\n  File \"/kaggle/working/yolov5/train.py\", line 623, in main\n    train(opt.hyp, opt, device, callbacks)\n  File \"/kaggle/working/yolov5/train.py\", line 382, in train\n    pred = model(imgs)  # forward\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py\", line 185, in forward\n    outputs = self.parallel_apply(replicas, inputs, module_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py\", line 200, in parallel_apply\n    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 110, in parallel_apply\n    output.reraise()\n  File \"/opt/conda/lib/python3.10/site-packages/torch/_utils.py\", line 694, in reraise\n    raise exception\ntorch.cuda.OutOfMemoryError: Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 85, in _worker\n    output = module(*input, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/kaggle/working/yolov5/models/yolo.py\", line 263, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File \"/kaggle/working/yolov5/models/yolo.py\", line 167, in _forward_once\n    x = m(x)  # run\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/kaggle/working/yolov5/models/common.py\", line 238, in forward\n    return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), 1))\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215, in forward\n    input = module(input)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/kaggle/working/yolov5/models/common.py\", line 175, in forward\n    return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/kaggle/working/yolov5/models/common.py\", line 86, in forward\n    return self.act(self.bn(self.conv(x)))\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 460, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 416.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 115.06 MiB is free. Process 22341 has 14.63 GiB memory in use. Of the allocated memory 14.32 GiB is allocated by PyTorch, and 56.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\nTraceback (most recent call last):\n  File \"/kaggle/working/yolov5/train.py\", line 848, in <module>\n    main(opt)\n  File \"/kaggle/working/yolov5/train.py\", line 623, in main\n    train(opt.hyp, opt, device, callbacks)\n  File \"/kaggle/working/yolov5/train.py\", line 382, in train\n    pred = model(imgs)  # forward\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py\", line 185, in forward\n    outputs = self.parallel_apply(replicas, inputs, module_kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py\", line 200, in parallel_apply\n    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 110, in parallel_apply\n    output.reraise()\n  File \"/opt/conda/lib/python3.10/site-packages/torch/_utils.py\", line 694, in reraise\n    raise exception\ntorch.cuda.OutOfMemoryError: Caught OutOfMemoryError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\", line 85, in _worker\n    output = module(*input, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/kaggle/working/yolov5/models/yolo.py\", line 263, in forward\n    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n  File \"/kaggle/working/yolov5/models/yolo.py\", line 167, in _forward_once\n    x = m(x)  # run\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/kaggle/working/yolov5/models/common.py\", line 238, in forward\n    return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), 1))\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215, in forward\n    input = module(input)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/kaggle/working/yolov5/models/common.py\", line 175, in forward\n    return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/kaggle/working/yolov5/models/common.py\", line 86, in forward\n    return self.act(self.bn(self.conv(x)))\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 460, in forward\n    return self._conv_forward(input, self.weight, self.bias)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py\", line 456, in _conv_forward\n    return F.conv2d(input, weight, bias, self.stride,\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 416.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 115.06 MiB is free. Process 22341 has 14.63 GiB memory in use. Of the allocated memory 14.32 GiB is allocated by PyTorch, and 56.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# !zip -r /content/file.zip /content/yolov5/runs/train/lab2_small","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y1Sf0royQn-s","executionInfo":{"status":"ok","timestamp":1712908610102,"user_tz":-420,"elapsed":2251,"user":{"displayName":"Даниил Владимирович Маковецкий","userId":"12330401444605609021"}},"outputId":"f5cc8dc6-412a-42e9-8d10-d5628ba874ab","execution":{"iopub.status.busy":"2024-04-13T17:52:34.613959Z","iopub.status.idle":"2024-04-13T17:52:34.614269Z","shell.execute_reply.started":"2024-04-13T17:52:34.614117Z","shell.execute_reply":"2024-04-13T17:52:34.614129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Какие ещё ключи есть у `train.py`? Идём в скрипт и находим вот такую часть кода, читаем её:\n\n```python\ndef parse_opt(known=False):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--weights', type=str, default=ROOT / 'yolov5s.pt', help='initial weights path')\n    parser.add_argument('--cfg', type=str, default='', help='model.yaml path')\n    parser.add_argument('--data', type=str, default=ROOT / 'data/coco128.yaml', help='dataset.yaml path')\n    parser.add_argument('--hyp', type=str, default=ROOT / 'data/hyps/hyp.scratch-low.yaml', help='hyperparameters path')\n    parser.add_argument('--epochs', type=int, default=100, help='total training epochs')\n    parser.add_argument('--batch-size', type=int, default=16, help='total batch size for all GPUs, -1 for autobatch')\n    parser.add_argument('--imgsz', '--img', '--img-size', type=int, default=640, help='train, val image size (pixels)')\n    parser.add_argument('--rect', action='store_true', help='rectangular training')\n    parser.add_argument('--resume', nargs='?', const=True, default=False, help='resume most recent training')\n    parser.add_argument('--nosave', action='store_true', help='only save final checkpoint')\n    parser.add_argument('--noval', action='store_true', help='only validate final epoch')\n    parser.add_argument('--noautoanchor', action='store_true', help='disable AutoAnchor')\n    parser.add_argument('--noplots', action='store_true', help='save no plot files')\n    parser.add_argument('--evolve', type=int, nargs='?', const=300, help='evolve hyperparameters for x generations')\n    parser.add_argument('--bucket', type=str, default='', help='gsutil bucket')\n    parser.add_argument('--cache', type=str, nargs='?', const='ram', help='image --cache ram/disk')\n    parser.add_argument('--image-weights', action='store_true', help='use weighted image selection for training')\n    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n    parser.add_argument('--multi-scale', action='store_true', help='vary img-size +/- 50%%')\n    parser.add_argument('--single-cls', action='store_true', help='train multi-class data as single-class')\n    parser.add_argument('--optimizer', type=str, choices=['SGD', 'Adam', 'AdamW'], default='SGD', help='optimizer')\n    parser.add_argument('--sync-bn', action='store_true', help='use SyncBatchNorm, only available in DDP mode')\n    parser.add_argument('--workers', type=int, default=8, help='max dataloader workers (per RANK in DDP mode)')\n    parser.add_argument('--project', default=ROOT / 'runs/train', help='save to project/name')\n    parser.add_argument('--name', default='exp', help='save to project/name')\n    parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')\n    parser.add_argument('--quad', action='store_true', help='quad dataloader')\n    parser.add_argument('--cos-lr', action='store_true', help='cosine LR scheduler')\n    parser.add_argument('--label-smoothing', type=float, default=0.0, help='Label smoothing epsilon')\n    parser.add_argument('--patience', type=int, default=100, help='EarlyStopping patience (epochs without improvement)')\n    parser.add_argument('--freeze', nargs='+', type=int, default=[0], help='Freeze layers: backbone=10, first3=0 1 2')\n    parser.add_argument('--save-period', type=int, default=-1, help='Save checkpoint every x epochs (disabled if < 1)')\n    parser.add_argument('--seed', type=int, default=0, help='Global training seed')\n    parser.add_argument('--local_rank', type=int, default=-1, help='Automatic DDP Multi-GPU argument, do not modify')\n\n    # Logger arguments\n    parser.add_argument('--entity', default=None, help='Entity')\n    parser.add_argument('--upload_dataset', nargs='?', const=True, default=False, help='Upload data, \"val\" option')\n    parser.add_argument('--bbox_interval', type=int, default=-1, help='Set bounding-box image logging interval')\n    parser.add_argument('--artifact_alias', type=str, default='latest', help='Version of dataset artifact to use')\n\n    return parser.parse_known_args()[0] if known else parser.parse_args()\n```\n\n","metadata":{"id":"VIGLfxrdvXSU"}},{"cell_type":"markdown","source":"(10 эпох - это достаточно мало, да и сама эпоха у вас будет занимать гораздо больше времени, ведь coco128 - это маленький датасет для отладки)","metadata":{"id":"vRFlkxkhtGcb"}},{"cell_type":"markdown","source":"Приятная опция: прерванные эксперименты можно возобновлять (если нечаянно нажали ctrl + c или потерялось соединение с сервером). Так выглядит код повторного запуска обучения, если вы прервали его:","metadata":{"id":"i97CUWUqv9G3"}},{"cell_type":"code","source":"# !python train.py --data data/Objects365.yaml --hyp data/hyps/hyp.scratch-low.yaml --weights yolov5m.pt \\\n# --epochs 5 --batch-size 32 --optimizer SGD --name example_Objects365 --resume runs/train/example_Objects365/weight/last.pt","metadata":{"id":"N5avWGN8wNqx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712904024909,"user_tz":-420,"elapsed":14833,"user":{"displayName":"Даниил Владимирович Маковецкий","userId":"12330401444605609021"}},"outputId":"0f590a92-3b69-4b8a-9a7c-9e00955b7504","execution":{"iopub.status.busy":"2024-04-13T17:52:34.615620Z","iopub.status.idle":"2024-04-13T17:52:34.615933Z","shell.execute_reply.started":"2024-04-13T17:52:34.615777Z","shell.execute_reply":"2024-04-13T17:52:34.615790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Провалидировать модель можно при помощи val.py:","metadata":{"id":"nRUoZ9c9t-Rn"}},{"cell_type":"code","source":"!ls","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s4tFbmIMvf7X","executionInfo":{"status":"ok","timestamp":1712999764907,"user_tz":-420,"elapsed":266,"user":{"displayName":"Даниил Владимирович Маковецкий","userId":"12330401444605609021"}},"outputId":"9dba3e26-76a7-4d4f-a642-2fc8282d34ba","execution":{"iopub.status.busy":"2024-04-13T17:52:34.617090Z","iopub.status.idle":"2024-04-13T17:52:34.617439Z","shell.execute_reply.started":"2024-04-13T17:52:34.617249Z","shell.execute_reply":"2024-04-13T17:52:34.617262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !python val.py --weights best.pt --data Object-Detection-3/data.yaml","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35277,"status":"ok","timestamp":1712999857506,"user":{"displayName":"Даниил Владимирович Маковецкий","userId":"12330401444605609021"},"user_tz":-420},"id":"45DCA_znuQBj","outputId":"6ba8fba6-6022-4aab-9b53-eca7ac2300c5","execution":{"iopub.status.busy":"2024-04-13T17:52:34.618663Z","iopub.status.idle":"2024-04-13T17:52:34.618965Z","shell.execute_reply.started":"2024-04-13T17:52:34.618813Z","shell.execute_reply":"2024-04-13T17:52:34.618826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Если остались вопросы\n\n- Читаем скрипты в [репозитории](https://github.com/ultralytics/yolov5)\n- Читаем [документацию к репозиторию](https://github.com/ultralytics/yolov5#documentation)\n- Если остались вопросы, можно искать в [issues](https://github.com/ultralytics/yolov5/issues)","metadata":{"id":"r9mL-wtVowvl"}},{"cell_type":"code","source":"!ls","metadata":{"id":"J4N2_Z2H76sO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712904031948,"user_tz":-420,"elapsed":23,"user":{"displayName":"Даниил Владимирович Маковецкий","userId":"12330401444605609021"}},"outputId":"df0dbf95-80d1-4850-cac8-06521f2cb6f3","execution":{"iopub.status.busy":"2024-04-13T17:52:34.619899Z","iopub.status.idle":"2024-04-13T17:52:34.620199Z","shell.execute_reply.started":"2024-04-13T17:52:34.620048Z","shell.execute_reply":"2024-04-13T17:52:34.620060Z"},"trusted":true},"execution_count":null,"outputs":[]}]}